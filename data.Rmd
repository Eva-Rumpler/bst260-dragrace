---
title: "Data extraction and wrangling"
---

In order to conduct this project, I had to extract information on 14
seasons and the performances of 184 queens. Although some datasets are
available in packages and online, I had to extract information from 3
different data sources and combine them in a usable clean dataset.

My first data source is an R package called dragracer. The package
contains three datasets. rpdr_ep contains episode-level data for all
available seasons, such as observations about when the episode aired,
the number of queens in the episode, mini-challenge winners, who
appeared in the bottom for a given episode, and who was sent home.
rpdr_contestants is a data frame of contestant-level information,
including the contestant’s age, purported date of birth, hometown, and
how they fared across all episodes in their particular season.
rpdr_contep is episode-contestant-level data about how each contestant
fared in a particular episode in which they were. For my project, I have
extracted and combined information from two datasets: rpdr_contep and
rpdr_contestants.

The second data source I have investigated is the “No key no shade” API,
which also contains information on queens, seasons and episodes. I
explored this option (see code below), but then decided against using it
in my final dataset because the information on the three most recent
seasons was missing and I did not want to reduce the size of my sample.

The third data source I used is the RuPaul-Predict-A-Looza Tables. I
extracted data from google sheets available online. I extracted two
different datasets. all_contestant, which contains information on
contestant’s names, seasons, outcome, and instagram and twitter handles.
all_social_media contains information on number of twitter and intagram
followers at numerous time points for each of the queens. I decided to
only consider the number of twitter followers at the time the season
started airing, as not to confound my results by including followers
that may have been accured after the outcome took place. I thus filtered
out the number of followers on the month of season airing, and joined
this dataset with the all_contestant dataset that contains the
contestant’s names. The dataset all_contestant from the third source is
somewhat redundant with the rpdr_contestants dataset from the dirst data
source, but the naming of the contestants is not perfectly identical, so
I had to do some wrangling to be able to join the two different
datasources.

Overall, I extracted information from 4 different datasets and joined
them together. The top rows of each of these 4 datasets is shown in
Tables 1 to 4 below. The top 5 rows of the cleaned dataset
that I obtained at the end of the data wrangling is in Table 6 below. It is tidy with one row per contestant and each column
containing each of the variables that I am interested in for my
analyses.


Below are the top 5 rows of the four input datasets that I used. 

```{r echo = FALSE, message=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
```

```{r echo = FALSE}
all_social_media <- readRDS("./data/all_social_media.RDS")
all_contestant <- readRDS("./data/all_contestant.RDS")
rpdr_contep <- readRDS("./data/rpdr_contep.RDS")
rpdr_contestants <- readRDS("./data/rpdr_contestants.RDS")
# head(all_social_media)
# head(all_contestant)[1:4,]
# head(rpdr_contep)
# head(rpdr_contestants)

knitr::kable(head(all_social_media), caption = "Data input 1") %>% kable_styling(latex_options=c("HOLD_position","scale_down")) 
knitr::kable(head(all_contestant)[1:4,], caption = "Data input 2") %>% kable_styling(latex_options=c("HOLD_position","scale_down")) 
knitr::kable(head(rpdr_contep), caption = "Data input 3") %>% kable_styling(latex_options=c("HOLD_position","scale_down")) 
knitr::kable(head(rpdr_contestants), caption = "Data input 4") %>% kable_styling(latex_options = c("HOLD_position","scale_down")) # ""

```

Below are the top 5 rows of the clean tidy dataset that I created for my analyses.

```{r echo = FALSE}
clean_data <- readRDS("./data/clean_data.RDS")
#head(clean_data)
knitr::kable(head(clean_data), caption = "Final clean dataset") %>% kable_styling(latex_options=c("HOLD_position","scale_down")) 

clean_data_twitter <- readRDS("./data/clean_data_twitter.RDS")
knitr::kable(head(clean_data_twitter), caption = "Final clean dataset including twitter data") %>% kable_styling(latex_options=c("HOLD_position","scale_down")) 

```


